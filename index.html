
<head>
<title>Sarah Harvey</title>
</head>

<body>
<img
                src="Harvey_Sarah_circle.png" alt="Description: This is a picture of me"
                v:shapes="Picture_x0020_2" align="left" height="250">
  
<br>
<h2> Sarah Harvey, Ph.D. <br></h2>
     <br>
     Flatiron Research Fellow
     <br>
     Center for Computational Neuroscience, Flatiron Institute<br>
     <br>
     Orcid:  <a href="https://orcid.org/0000-0003-2601-7487">0000-0003-2601-7487</a> <br>
     My <a href="https://scholar.google.com/citations?user=Be6-rWoAAAAJ&hl=en"> Google Scholar </a> <br>
     My <a href="https://github.com/SarahHarvey"> Github </a>
     My <a href="SarahHarveyCV.pdf"> CV </a>
<p>
<br>
<br>
<br>
<p>
Hello! I am Sarah, a theoretical physics, neuroscience, and machine learning research fellow at the <a href="https://www.simonsfoundation.org/flatiron/" > Flatiron Institute</a>, which is a scientific research branch of the <a href="https://www.simonsfoundation.org/">
Simons Foundation</a>. 
   I am interested in the origin of intelligence, and how biological brains can solve complex computational problems much more efficiently than our artificial models.
 </p>
 <p> 
  I perform theoretical and computational research with the <a href="https://neurostatslab.org/" > Williams Lab</a>, and my work currently centers around understanding and developing meaningful ways to measure when neural systems are similar to each other, which is sometimes referred to as "representational similarity".  In deep networks, this involves answering questions such as "what important aspects of the representations have changed when I fine tune my network?" or "when should I conclude that two layers in two different deep network architectures have similar functional roles?"  
 </p>
 <p>
   On the neuroscience side, I think about understanding representational similarity as a prerequisite to determine when and if we have constructed a "good" model of a biological brain.   Furthermore, I don't think that we will "understand" biological brains until we understand how they come to be, both developmentally and evolutionarily, which implies an understanding of how neural systems change.  Methods for meaningful comparison between these systems are then a crucial step toward this end.   
</p>
<p>
I am a graduate of the <a href="https://appliedphysics.stanford.edu/">applied physics department</a> at Stanford University, where I was theorist in the <a href="https://ganguli-gang.stanford.edu/">
Ganguli Lab</a>.
In graduate school, I worked on using methods from nonequilibrium statistical physics and large deviation theory
to study biological computation, from the micoscopic scale of single receptor computations to macroscopic reinforcement learning.
My paper (with <a href="https://subhylahiri.github.io/"> Subhaneil Lahiri</a>) from this time studies thermodynamic limits on sensors modeled as continuous time Markov chains, using stochastic thermodynamics and large deviation theory.  We can place
interesting bounds on sensors of this type by first deriving a thermodynamic uncertainty relation for densities in subsets of Markov chain states.  We later applied this same mathematics to risk-aware Markov decision processes, with a paper forthcoming!
<!-- </p>
With Chris Stock and Sam Ocko, I also worked on a project deriving biologically plausible synaptic update rules that provably preserve the task
an RNN is trained to do, while also increasing the network robustness.  We can think of this synaptic update rule as traversing a manifold in synaptic weight space of networks
that perform exactly the same task, to find the network with the best noise robustness quality. 
<p> -->
<p>
Before Stanford I graduated from the wonderful University of Washington in Seattle, with Bachelor's degrees in <a href="https://phys.washington.edu/">
physics </a> and <a href="https://astro.washington.edu/">
astronomy</a>.  
</p>  
<p>
Links to my papers and preprints are listed below.  The preprints and published versions mostly have very similar or identical content.  Feel free to email me if you have questions or ideas.  However, I don't reliably respond to emails asking for advice about people I have worked with or places I have worked in the past.   
</p>

<h3>
<a name="Pubs"></a><i>
Publication Links</i></h3>
Joao Barbosa, Amin Nejatbakhsh, Lyndon Duong, Sarah E. Harvey, Scott L. Brincat, Markus Siegel, Earl K. Miller, and Alex H. Williams. (2025) <i> Quantifying Differences in Neural Population Activity With Shape Metrics</i>. Preprint: <a href="https://www.biorxiv.org/content/10.1101/2025.01.10.632411v1.abstract">biorxiv.org/content/10.1101/2025.01.10.632411v1</a>
<p>  
Sarah E. Harvey, David Lipshutz, Alex H. Williams. (2024). <i>What Representational Similarity Measures Imply about Decodable Information.</i> UniReps 2024.  Preprint:  <a href="https://arxiv.org/abs/2411.08197">https://arxiv.org/abs/2411.08197</a>.  Code: <a href="https://github.com/SarahHarvey/decoding-similarity">github.com/SarahHarvey/decoding-similarity</a>
<p>
Jenelle Feather, David Lipshutz, Sarah E. Harvey, Alex H. Williams, Eero P. Simoncelli. (2024). <i>Discriminating image representations with principal distortions. </i> ICLR 2025.  Preprint:  <a href="https://arxiv.org/abs/2410.15433">https://arxiv.org/abs/2410.15433</a>.
<p>  
Sarah E. Harvey, Brett W. Larsen, Alex H. Williams. (2024). <i>Duality of Bures and Shape Distances with Implications for Comparing Neural Representations.</i> UniReps 2023.  Preprint:  <a href="https://arxiv.org/abs/2311.11436">https://arxiv.org/abs/2311.11436</a>.
<p>
Dean A. Pospisil, Brett W. Larsen, Sarah E. Harvey, Alex H. Williams.  (2023).  <i>Estimating Shape Distances on Neural Representations with Limited Samples.</i>  ICLR 2024.  Preprint:  <a href="https://arxiv.org/abs/2310.05742">https://arxiv.org/abs/2310.05742</a>.
<p>  
Sarah E. Harvey, Subhaneil Lahiri, Surya Ganguli. (2022). <i>Universal energy-accuracy tradeoffs in nonequilibrium cellular sensing.</i>  Physical Review E <a href="https://journals.aps.org/pre/abstract/10.1103/PhysRevE.108.014403"> (link)</a>.  Preprint: <a href="https://arxiv.org/abs/2002.10567">https://arxiv.org/abs/2002.10567</a>.
<p>
Christopher H. Stock, Sarah E. Harvey, Samuel A. Ocko, Surya Ganguli. (2021). <i>Synaptic balancing: a biologically plausible local learning rule that provably increases neural network noise robustness without sacrificing task performance.  </i> PLOS Computational Biology <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010418"> (link)</a>.  Preprint: <a href="https://arxiv.org/abs/2107.08530">https://arxiv.org/abs/2107.08530</a>.
<p>
Todd Karin, Xiayu Linpeng, M. M. Glazov, M. V. Durnev, E. L. Ivchenko, Sarah Harvey, Ashish K. Rai, Arne Ludwig, Andreas D. Wieck, and Kai-Mei C. Fu.  (2016).  <i>Giant permanent dipole moment of two-dimensional excitons bound to a single stacking fault.</i>  Physical Review B, 94(4). doi:10.1103/physrevb.94.041201. (<a href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.94.041201">link</a>)
</span></p>
<h3>
<a name="Education"></a><i>
Education</i></h3>
<p class="p6"><span class="s3"><a href="http://www.phys.washington.edu/">University of Washington</a></span><span class="s1">                       B.S., Physics and Astronomy, <i>summa cum laude</i>, 2015</span></p>
<p class="p6"><span class="s3"><a href="https://appliedphysics.stanford.edu/">Stanford University</a></span><span class="s1">                            Ph.D., Applied Physics, 2022, my thesis:  <a href="https://searchworks.stanford.edu/view/14423017"><i>Combating noise and uncertainty in biophysical models</i></a>  </span></p>
</p>

<h3>
<a name="Talks"></a><i>
Talks</i></h3>

<ul>
  <li> Contributed talk at "SAND: Statistical Analysis of Neural Data" workshop (In person, June 2025). <a href="posters/decoding_poster_flatiron_internal_2025.pdf">poster</a>
  <li> Contributed talk at "UniReps: Unifying Representations in Neural Models" NeurIPS workshop (In person, December 2024).  (<a href="posters/poster_decoding_unireps_2024.pdf">poster</a>)
  <li> Contributed talk at Cognitive Computational Neuroscience conference (In person, August 2024). <a href="https://www.youtube.com/watch?v=d-AFzypJSCY">video </a> </li>
  <li> Panelist at ReAlign: First Workshop on Representational Alignment (ICLR 2024 workshop).
  <li> Contributed talk at "UniReps: Unifying Representations in Neural Models" NeurIPS workshop (In person, December 2023).  (<a href="posters/UniReps2023_poster_portrait.pdf">poster</a>)
  <li> Contributed talk at "Towards a theory of artificial and biological neural networks, a Les Houches workshop" (In person, February 2023).
  <li> Invited talk at BIRS conference "Mathematical Models in Biology: from Information Theory to Thermodynamics" (Online, July 2020).  <a href="https://www.birs.ca/events/2020/5-day-workshops/20w5074/videos/watch/202007271004-Harvey.html">video </a> </li>
  <li> APS 2020 abstract and presentation slides <a href="https://meetings.aps.org/Meeting/MAR20/Session/A25.6">here</a>
  <li> Bernstein 2019:  A local synaptic balancing rule for homeostatic plasticity (<a href="posters/Bernstein_Poster.pdf">poster</a>)
</ul>

<h3>
<a name="Teaching"></a><i>
Teaching </i></h3>
  <ul>
  <li> <i>Summer 2022:</i>  Stanford Program for Inspiring the Next Generation of Women in Physics (SPINWIP) counselor.  Program website: <a href="https://physics.stanford.edu/inclusion/spinwip">https://physics.stanford.edu/inclusion/spinwip</a></li>
  <li> <i>Summer 2021:</i>  Methods in Computational Neuroscience Research Facilitator.  Summer school website: <a href="https://www.mbl.edu/mcn/">https://www.mbl.edu/mcn/</a></li>
  <li> <i>Winter 2019:</i>  NBIO 228 (Mathematical Tools for Neuroscience).  Developed curriculum, lectures, and homework assignments for the core mathematical
methods class required for first year neuroscience PhD students at Stanford. <a href="519/course.html">Notes</a> </li>
</ul>

<h3>
<i>Honors, Awards, Programs</i></h3>
<ul>
<li> 2024 UniReps Best Paper Award (Proceedings) for <i> What Representational Similarity Measures Imply about Decodable Information</i>. <a href="posters/poster_decoding_cosyne_2025.pdf">(poster)</a>  </li></li>   
<li> 2023 UniReps Best Proceeding Honorable Mention for <i>Duality of Bures and Shape Distances with Implications for Comparing Neural Representations</i>.  </li> 
<li> 2021 Beg Rohu Summer School Participant <a href="posters/BegRohu_poster.pdf">(poster)</a>  </li>
<li>2018 Center for Mind, Brain, Computation and Technology Graduate Trainee</li>
<li>
2017 Methods in Computational Neuroscience Summer School student, Woods Hole, MA.
 </li>
<li>
2016 National Defense Science and Engineering Graduate Fellowship <a href="https://ndseg.sysplus.com/" >(NDSEG)</a> recipient</li>
<li>
2015 Stanford Graduate Fellowship, William R. Hewlett Fellow </li>
<li>
2014 Mary L. Boas Endowed Scholarship in Physics</li>
<li>
2010 - 2014 Washington NASA Space Grant Scholar
<li>
2010 - 2014 Mary Gates Endowment for Students
<li>
Phi Beta Kappa honors society, Sigma Pi Sigma physics honors society
</ul>
</li>

</ul>
</ul>

<h3>
<i>Some other stuff I enjoy</i></h3>

<a href="https://oeis.org/">
OEIS</a>
<br>
Electronics and Ham radio: KI7UXI
<br>
Drawing
<br>
Analog Photography
<br>

<!--<a href="drawing.html">Drawing</a> -->


<!-- Bio/Resume -->
<hr>
<pre>
US mail: Sarah Harvey
         162 Fifth Avenue
         Center for Computational Neuroscience
         New York, NY  10010
Email:   sharvey@flatironinstitute.org
Bluesky: @sarah-harvey.bsky.social  
</pre>

<hr>
<address>
<a href="https://sarahharvey.github.io/">Sarah Harvey</a>
&lt;<a href="mailto:sharvey@flatironinstitute.org">
  sharvey@flatironinstitute.org</a>&gt;
</address> Last modified: 1/26
</body>
